{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3942aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a73df",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469331a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "#Opening the website \n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46220fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the rank by passing the xpath\n",
    "rank = driver.find_elements_by_xpath('//td[@align=\"center\"][1]')\n",
    "Rank=[]\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "#Scraping the rank by passing the xpath\n",
    "\n",
    "name = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]/a')\n",
    "# Making a list and storing all the scraped data into it\n",
    "Name=[]\n",
    "for i in name:\n",
    "    if i.text is None :\n",
    "        Name.append(\"-\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "#Scraping the artist by passing the xpath    \n",
    "upload = driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "# Making a list and storing all the scraped data into it\n",
    "Uploader=[]\n",
    "for i in upload:\n",
    "    if i.text is None :\n",
    "        Uploader.append(\"-\") \n",
    "    else:\n",
    "        Uploader.append(i.text)\n",
    "        \n",
    "#Scraping the views by passing the xpath        \n",
    "view=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "# Making a list and storing all the scraped data into it\n",
    "Views=[]\n",
    "for i in view:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "#Scraping the date by passing the xpath   \n",
    "date=driver.find_elements_by_xpath('//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "# Making a list and storing all the scraped data into it\n",
    "Date=[]\n",
    "for i in date:\n",
    "    Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4314afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=Rank[:38]\n",
    "Uploader=Uploader[:38]\n",
    "Views=Views[:38]\n",
    "Date=Date[:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59e12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Youtube=pd.DataFrame({})\n",
    "Youtube['Rank']=Rank\n",
    "Youtube['Name']=Name\n",
    "Youtube['Artist']=Uploader\n",
    "Youtube['Views']=Views\n",
    "Youtube['Date']=Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a10dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.95</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.44</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.54</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.38</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.17</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.29</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.25</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.22</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.11</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.98</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.45</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.45</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.38</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.34</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.29</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.15</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.10</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.10</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.07</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.07</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.06</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.06</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.02</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Pinkfong</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.94</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.89</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.88</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Psy</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.87</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.85</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>7,037,500,000</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>November 2, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[118]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>August 4, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[28]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>July 10, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[35]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>November 24, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[119]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>February 19, 2010</td>\n",
       "      <td>July 16, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>93</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>November 24, 2009</td>\n",
       "      <td>April 14, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>171</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>May 22, 2007</td>\n",
       "      <td>October 25, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>176</td>\n",
       "      <td>jawed</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>April 6, 2006</td>\n",
       "      <td>May 2, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                              Name                          Artist  \\\n",
       "0      1.                  Baby Shark Dance  Pinkfong Kids' Songs & Stories   \n",
       "1      2.                         Despacito                      Luis Fonsi   \n",
       "2      3.              Johny Johny Yes Papa                     LooLoo Kids   \n",
       "3      4.                      Shape of You                      Ed Sheeran   \n",
       "4      5.                     See You Again                     Wiz Khalifa   \n",
       "5      6.                       Uptown Funk                      Get Movies   \n",
       "6      7.                     Gangnam Style      Cocomelon – Nursery Rhymes   \n",
       "7      8.                             Sugar                     Miroshka TV   \n",
       "8      9.                    Dame Tu Cosita                     Mark Ronson   \n",
       "9     10.                             Sorry                             Psy   \n",
       "10    11.                              Roar                       ChuChu TV   \n",
       "11    12.                    Counting Stars                        Maroon 5   \n",
       "12    13.                 Thinking Out Loud                       El Chombo   \n",
       "13    14.                        Dark Horse                   Justin Bieber   \n",
       "14    15.                             Faded                      Katy Perry   \n",
       "15    16.                      Shake It Off                     OneRepublic   \n",
       "16    17.                    Girls Like You                      Ed Sheeran   \n",
       "17    18.                           Lean On      Cocomelon – Nursery Rhymes   \n",
       "18    19.                          Bailando                      Katy Perry   \n",
       "19    20.                        Let Her Go                     Alan Walker   \n",
       "20    21.                          Mi Gente                    Taylor Swift   \n",
       "21    22.                           Perfect                        Maroon 5   \n",
       "22    23.  Waka Waka (This Time for Africa)                     Major Lazer   \n",
       "23    24.                            Axel F                Enrique Iglesias   \n",
       "24    25.                             Hello                       Passenger   \n",
       "25    26.                          Pinkfong                        J Balvin   \n",
       "26    27.                        Luis Fonsi                      Ed Sheeran   \n",
       "27    28.                       Wiz Khalifa                         Shakira   \n",
       "28    29.                               Psy                      Crazy Frog   \n",
       "29    30.                     Justin Bieber                           Adele   \n",
       "30                                Lady Gaga                   7,037,500,000   \n",
       "31  [118]                    Judson Laipply                   2,993,700,000   \n",
       "32   [28]                       RCA Records                   2,894,000,000   \n",
       "33   [35]                    Judson Laipply                     803,700,000   \n",
       "34  [119]                    Judson Laipply                     245,400,000   \n",
       "35     93                             Smosh                     178,400,000   \n",
       "36    171                        Nikesoccer                     128,900,000   \n",
       "37    176                             jawed                     118,900,000   \n",
       "\n",
       "                Views               Date  \n",
       "0                8.95      June 17, 2016  \n",
       "1                7.44   January 12, 2017  \n",
       "2                5.54    October 8, 2016  \n",
       "3                5.38   January 30, 2017  \n",
       "4                5.17      April 6, 2015  \n",
       "5                4.44   January 31, 2012  \n",
       "6                4.29        May 2, 2018  \n",
       "7                4.25  February 27, 2018  \n",
       "8                4.22  November 19, 2014  \n",
       "9                4.11      July 15, 2012  \n",
       "10               3.98      March 6, 2014  \n",
       "11               3.50   January 14, 2015  \n",
       "12               3.45      April 5, 2018  \n",
       "13               3.45   October 22, 2015  \n",
       "14               3.38  September 5, 2013  \n",
       "15               3.34       May 31, 2013  \n",
       "16               3.29    October 7, 2014  \n",
       "17               3.15       May 24, 2018  \n",
       "18               3.10  February 20, 2014  \n",
       "19               3.10   December 3, 2015  \n",
       "20               3.07    August 18, 2014  \n",
       "21               3.07       May 31, 2018  \n",
       "22               3.06     March 22, 2015  \n",
       "23               3.06     April 11, 2014  \n",
       "24               3.02      July 25, 2012  \n",
       "25               2.94      June 29, 2017  \n",
       "26               2.89   November 9, 2017  \n",
       "27               2.88       June 4, 2010  \n",
       "28               2.87      June 16, 2009  \n",
       "29               2.85   October 22, 2015  \n",
       "30      June 17, 2016   November 2, 2020  \n",
       "31   January 12, 2017     August 4, 2017  \n",
       "32      April 6, 2015      July 10, 2017  \n",
       "33      July 15, 2012  November 24, 2012  \n",
       "34  February 19, 2010      July 16, 2010  \n",
       "35  November 24, 2009     April 14, 2010  \n",
       "36       May 22, 2007   October 25, 2009  \n",
       "37      April 6, 2006        May 2, 2009  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a00dee",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a2e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(4)\n",
    "# Opening the homepage of bcci website\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "# Clickking on drop down navigation bar On International\n",
    "driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\").click()\n",
    "# Selecting the Fixtures from International\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2759b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists of each column\n",
    "Match=[]\n",
    "Place=[]\n",
    "Series=[]\n",
    "Time=[]\n",
    "Date=[]\n",
    "Month=[]\n",
    "\n",
    "# Scraping the title by passing xpath\n",
    "match=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "# Appending all the match titles to the list (Match) using for loop\n",
    "for i in match:\n",
    "    Match.append(i.text)\n",
    "# Scraping the place by passing xpath\n",
    "place = driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "# Appending all the places to the list (Place) using for loop\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "# Scraping the Series by passing xpath\n",
    "series=driver.find_elements_by_xpath(\"//div[@class='fixture__info u-skewed']/div[1]/span[1]\")\n",
    "# Appending all the Series to the list (Series) using for loop\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "# Scraping the time by passing xpath\n",
    "time=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[2]\")\n",
    "# Appending all the match timings to the list (Time) using for loop\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "# Scraping the date by passing xpath\n",
    "date=driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']/span\")\n",
    "Date=[]\n",
    "# Appending all the match dates to the list (Date) using for loop\n",
    "for i in date:\n",
    "    Date.append(i.text)\n",
    "# Scraping the month by passing xpath\n",
    "month=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[1]\")\n",
    "# Appending all the months to the list (Month) using for loop\n",
    "for i in month:\n",
    "    Month.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a68f539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ODI</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>18</td>\n",
       "      <td>JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>ODI</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>20</td>\n",
       "      <td>JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>ODI</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>23</td>\n",
       "      <td>JULY</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>T20I</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>25</td>\n",
       "      <td>JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>T20I</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>27</td>\n",
       "      <td>JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>T20I</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>29</td>\n",
       "      <td>JULY</td>\n",
       "      <td>20:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>TEST</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title Series                         Place Date      Month       Time\n",
       "0      1st ODI    ODI  R Premadasa Stadium, Colombo   18       JULY  15:00 IST\n",
       "1      2nd ODI    ODI  R Premadasa Stadium, Colombo   20       JULY  15:00 IST\n",
       "2      3rd ODI    ODI  R Premadasa Stadium, Colombo   23       JULY  15:00 IST\n",
       "3     1st T20I   T20I  R Premadasa Stadium, Colombo   25       JULY  20:00 IST\n",
       "4     2nd T20I   T20I  R Premadasa Stadium, Colombo   27       JULY  20:00 IST\n",
       "5     3rd T20I   T20I  R Premadasa Stadium, Colombo   29       JULY  20:00 IST\n",
       "6     1st Test   TEST      Trent Bridge, Nottingham   04     AUGUST  15:30 IST\n",
       "7     2nd Test   TEST                Lord's, London   12     AUGUST  15:30 IST\n",
       "8     3rd Test   TEST             Headingley, Leeds   25     AUGUST  15:30 IST\n",
       "9     4th Test   TEST              The Oval, London   02  SEPTEMBER  15:30 IST\n",
       "10    5th Test   TEST      Old Trafford, Manchester   10  SEPTEMBER  15:30 IST"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCCI=pd.DataFrame({})\n",
    "BCCI['Match Title']=Match\n",
    "BCCI['Series']=Series\n",
    "BCCI['Place']=Place\n",
    "BCCI['Date']=Date\n",
    "BCCI['Month']=Month\n",
    "BCCI['Time']=Time\n",
    "# Viewing the Scraped data\n",
    "BCCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b9259",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30dea1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# Opening the homepage of guru99 website\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "# Clicking on Selenium \n",
    "driver.find_element_by_xpath('//ul[@class=\"menu\"]/li[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc691ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Selenium Exception Handling (Common Exceptions List)\n",
    "driver.find_element_by_xpath('//*[@id=\"g-mainbar\"]/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ceebc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the names by passing xpath\n",
    "name=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "#Scraping the description by passing xpath\n",
    "desc=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "# Making list named \"Name\" and appending all the exception names into it\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "\n",
    "# Making list named \"Desc\" and appending all the Description of all the exceptions into it\n",
    "Desc=[]\n",
    "for i in desc:\n",
    "    Desc.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74fee238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "0                        Exception name   \n",
       "1            ElementNotVisibleException   \n",
       "2         ElementNotSelectableException   \n",
       "3                NoSuchElementException   \n",
       "4                  NoSuchFrameException   \n",
       "5               NoAlertPresentException   \n",
       "6                 NoSuchWindowException   \n",
       "7        StaleElementReferenceException   \n",
       "8              SessionNotFoundException   \n",
       "9                      TimeoutException   \n",
       "10                   WebDriverException   \n",
       "11            ConnectionClosedException   \n",
       "12     ElementClickInterceptedException   \n",
       "13      ElementNotInteractableException   \n",
       "14             ErrorInResponseException   \n",
       "15  ErrorHandler.UnknownServerException   \n",
       "16         ImeActivationFailedException   \n",
       "17             ImeNotAvailableException   \n",
       "18         InsecureCertificateException   \n",
       "19             InvalidArgumentException   \n",
       "20         InvalidCookieDomainException   \n",
       "21          InvalidCoordinatesException   \n",
       "22          InvalidElementStateExceptio   \n",
       "23            InvalidSessionIdException   \n",
       "24       InvalidSwitchToTargetException   \n",
       "25                  JavascriptException   \n",
       "26                        JsonException   \n",
       "27             NoSuchAttributeException   \n",
       "28       MoveTargetOutOfBoundsException   \n",
       "29               NoSuchContextException   \n",
       "30                NoSuchCookieException   \n",
       "31                    NotFoundException   \n",
       "32          RemoteDriverServerException   \n",
       "33                  ScreenshotException   \n",
       "34           SessionNotCreatedException   \n",
       "35           UnableToSetCookieException   \n",
       "36           UnexpectedTagNameException   \n",
       "37              UnhandledAlertException   \n",
       "38      UnexpectedAlertPresentException   \n",
       "39               UnknownMethodException   \n",
       "40          UnreachableBrowserException   \n",
       "41          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0                                         Description  \n",
       "1   This type of Selenium exception occurs when an...  \n",
       "2   This Selenium exception occurs when an element...  \n",
       "3   This Exception occurs if an element could not ...  \n",
       "4   This Exception occurs if the frame target to b...  \n",
       "5   This Exception occurs when you switch to no pr...  \n",
       "6   This Exception occurs if the window target to ...  \n",
       "7   This Selenium exception occurs happens when th...  \n",
       "8   The WebDriver is acting after you quit the bro...  \n",
       "9   Thrown when there is not enough time for a com...  \n",
       "10  This Exception takes place when the WebDriver ...  \n",
       "11  This type of Exception takes place when there ...  \n",
       "12  The command may not be completed as the elemen...  \n",
       "13  This Selenium exception is thrown when any ele...  \n",
       "14  This happens while interacting with the Firefo...  \n",
       "15  Exception is used as a placeholder in case if ...  \n",
       "16  This expectation will occur when IME engine ac...  \n",
       "17    It takes place when IME support is unavailable.  \n",
       "18  Navigation made the user agent to hit a certif...  \n",
       "19  It occurs when an argument does not belong to ...  \n",
       "20  This happens when you try to add a cookie unde...  \n",
       "21  This type of Exception matches an interacting ...  \n",
       "22  It occurs when command can't be finished when ...  \n",
       "23  This Exception took place when the given sessi...  \n",
       "24  This occurs when the frame or window target to...  \n",
       "25  This issue occurs while executing JavaScript g...  \n",
       "26  It occurs when you afford to get the session w...  \n",
       "27  This kind of Exception occurs when the attribu...  \n",
       "28  It takes place if the target provided to the A...  \n",
       "29           ContextAware does mobile device testing.  \n",
       "30  This Exception occurs when no cookie matching ...  \n",
       "31  This Exception is a subclass of WebDriverExcep...  \n",
       "32  This Selenium exception is thrown when the ser...  \n",
       "33            It is not possible to capture a screen.  \n",
       "34  It happens when a new session could not be suc...  \n",
       "35  This occurs if a driver is unable to set a coo...  \n",
       "36  Happens if a support class did not get a web e...  \n",
       "37  This expectation occurs when there is an alert...  \n",
       "38  It occurs when there is the appearance of an u...  \n",
       "39  This Exception happens when the requested comm...  \n",
       "40  This Exception occurs only when the browser is...  \n",
       "41  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving all the scraped data into a DataFrame named \"Exceptions\"\n",
    "Exceptions=pd.DataFrame({})\n",
    "Exceptions['Name']=Name\n",
    "Exceptions['Description']=Desc\n",
    "# Viewing the DataFrame(Exceptions)\n",
    "Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e76e74",
   "metadata": {},
   "source": [
    "# 4>Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP at current price (19-20) D) GSDP at current price (18-19) E) Share(18-19) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec14f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "# Opening the homepage of website\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "# Clicking on Read more\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[2]/p[2]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5eced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Economy\n",
    "driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "249dd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start and end for scraping SGDP\n",
    "tr_start=0\n",
    "tr_end=33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7a89f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the rank by passing xpath\n",
    "rank = driver.find_elements_by_xpath('//td[@class=\"data1\"]')\n",
    "# Scraping the state by passing xpath\n",
    "state=driver.find_elements_by_xpath('//td[@class=\"name\"]')\n",
    "# Scraping the GSDPs of year 18 & 19 by passing xpath\n",
    "gsdp_1819=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[4]')\n",
    "# Scraping the GSDPs of year 19 &20 by passing xpath\n",
    "gsdp_1920=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[3]')\n",
    "# Scraping the GDP of each state by passing xpath\n",
    "gdp=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[6]')\n",
    "# Scraping the share of state by passing xpath\n",
    "share=driver.find_elements_by_xpath('//tr[@role=\"row\"]/td[5]')\n",
    "\n",
    "# Making  a list named Rank and appending all the ranks in it\n",
    "Rank=[]\n",
    "for i in rank[tr_start:tr_end]:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "state=driver.find_elements_by_xpath('//td[@class=\"name\"]')\n",
    "# Making  a list named State and appending all the states in it\n",
    "State=[]\n",
    "for i in state[tr_start:tr_end]:\n",
    "    State.append(i.text)\n",
    "# Making  a list named GSDP_1819 and appending all the GSDPs of year 18 & 19  in it\n",
    "GSDP_1819=[]\n",
    "for i in gsdp_1819[tr_start:tr_end]:\n",
    "    GSDP_1819.append(i.text)\n",
    "# Making  a list named GSDP_1920 and appending all the GSDPs of year 19 & 20  in it   \n",
    "GSDP_1920=[]\n",
    "for i in gsdp_1920[tr_start:tr_end]:\n",
    "    GSDP_1920.append(i.text)\n",
    "    \n",
    "# Making  a list named Share and appending all the states shares in it\n",
    "Share=[]\n",
    "for i in share[tr_start:tr_end]:\n",
    "    Share.append(i.text)\n",
    "# Making  a list named GDP and appending all the states GDP in it    \n",
    "GDP=[]\n",
    "for i in gdp[tr_start:tr_end]:\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f25452d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_1819</th>\n",
       "      <th>GSDP_1920</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Guyana</td>\n",
       "      <td>16.394</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>South America</td>\n",
       "      <td>1.989</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>96.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>5.556</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>15.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>Africa</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>7.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>5.035</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>329.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2.473</td>\n",
       "      <td>6</td>\n",
       "      <td>145</td>\n",
       "      <td>361.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>-8.894</td>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "      <td>81.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>169</td>\n",
       "      <td>Asia</td>\n",
       "      <td>4.748</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>668.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>6.500</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>340.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>Asia</td>\n",
       "      <td>4.234</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>418.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>124</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>5.956</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>61.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>166</td>\n",
       "      <td>Africa</td>\n",
       "      <td>8.437</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>14,722.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>4.972</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>15.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46</td>\n",
       "      <td>Asia</td>\n",
       "      <td>6.042</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>719.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>148</td>\n",
       "      <td>Taiwan Province of China</td>\n",
       "      <td>4.991</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>57.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>174</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2.539</td>\n",
       "      <td>16</td>\n",
       "      <td>140</td>\n",
       "      <td>635.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1.646</td>\n",
       "      <td>17</td>\n",
       "      <td>161</td>\n",
       "      <td>12.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>Asia</td>\n",
       "      <td>6.890</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>2.658</td>\n",
       "      <td>19</td>\n",
       "      <td>136</td>\n",
       "      <td>63.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>146</td>\n",
       "      <td>Europe</td>\n",
       "      <td>4.639</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "      <td>68.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>5.197</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>24.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>145</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4.256</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>16.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>34</td>\n",
       "      <td>China</td>\n",
       "      <td>4.559</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>47.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>121</td>\n",
       "      <td>Asia</td>\n",
       "      <td>1.550</td>\n",
       "      <td>24</td>\n",
       "      <td>162</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>Benin</td>\n",
       "      <td>3.500</td>\n",
       "      <td>25</td>\n",
       "      <td>102</td>\n",
       "      <td>7.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>191</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2.200</td>\n",
       "      <td>26</td>\n",
       "      <td>149</td>\n",
       "      <td>8.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>66</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2.477</td>\n",
       "      <td>27</td>\n",
       "      <td>144</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>155</td>\n",
       "      <td>Europe</td>\n",
       "      <td>6.000</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>1.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>3.491</td>\n",
       "      <td>29</td>\n",
       "      <td>104</td>\n",
       "      <td>2.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>52</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.770</td>\n",
       "      <td>30</td>\n",
       "      <td>91</td>\n",
       "      <td>49.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21</td>\n",
       "      <td>Islamic Republic of Iran</td>\n",
       "      <td>7.560</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>99.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Asia</td>\n",
       "      <td>5.690</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>10.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>1.496</td>\n",
       "      <td>33</td>\n",
       "      <td>164</td>\n",
       "      <td>262.799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                     State GSDP_1819 GSDP_1920 Share GDP($ billion)\n",
       "0     1                    Guyana    16.394         1     4          5.766\n",
       "1     4             South America     1.989         2   155         96.611\n",
       "2   152                  Ethiopia     5.556         3    31         15.455\n",
       "3    82                    Africa     5.000         4    46          7.997\n",
       "4     2                    Guinea     5.035         5    40        329.120\n",
       "5   155                    Africa     2.473         6   145        361.847\n",
       "6    64                Tajikistan    -8.894         7   191         81.257\n",
       "7   169                      Asia     4.748         8    52        668.510\n",
       "8     3                Bangladesh     6.500         9    16        340.821\n",
       "9    31                      Asia     4.234        10    71        418.716\n",
       "10  124                     Egypt     5.956        11    25         61.402\n",
       "11  166                    Africa     8.437        12     9     14,722.840\n",
       "12    4                   Myanmar     4.972        13    49         15.193\n",
       "13   46                      Asia     6.042        14    21        719.537\n",
       "14  148  Taiwan Province of China     4.991        15    48         57.706\n",
       "15  174                      Asia     2.539        16   140        635.724\n",
       "16    5                   Vietnam     1.646        17   161         12.016\n",
       "17   40                      Asia     6.890        18    13         13.698\n",
       "18   41                   Ireland     2.658        19   136         63.244\n",
       "19  146                    Europe     4.639        20    57         68.418\n",
       "20    6             Côte d'Ivoire     5.197        21    37         24.448\n",
       "21  145                    Africa     4.256        22    70         16.541\n",
       "22   34                     China     4.559        23    58         47.354\n",
       "23  121                      Asia     1.550        24   162          0.114\n",
       "24    7                     Benin     3.500        25   102          7.495\n",
       "25  191                    Africa     2.200        26   149          8.488\n",
       "26   66                    Turkey     2.477        27   144          0.048\n",
       "27  155                    Europe     6.000        28    23          1.913\n",
       "28    8                Uzbekistan     3.491        29   104          2.366\n",
       "29   52                      Asia     3.770        30    91         49.077\n",
       "30   21  Islamic Republic of Iran     7.560        31    10         99.287\n",
       "31   31                      Asia     5.690        32    30         10.372\n",
       "32    9         Brunei Darussalam     1.496        33   164        262.799"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame\n",
    "Stats=pd.DataFrame({})\n",
    "Stats['Rank']=Rank\n",
    "Stats['State']=State\n",
    "Stats['GSDP_1819']=GSDP_1819\n",
    "Stats['GSDP_1920']=GSDP_1920\n",
    "Stats['Share']=Share\n",
    "Stats['GDP($ billion)']=GDP\n",
    "#Viewing the DataFrame\n",
    "Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3f1ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank                    State GSDP_1819 GSDP_1920 Share GDP($ billion)\n",
      "   1                   Guyana    16.394         1     4          5.766\n",
      "   4            South America     1.989         2   155         96.611\n",
      " 152                 Ethiopia     5.556         3    31         15.455\n",
      "  82                   Africa     5.000         4    46          7.997\n",
      "   2                   Guinea     5.035         5    40        329.120\n",
      " 155                   Africa     2.473         6   145        361.847\n",
      "  64               Tajikistan    -8.894         7   191         81.257\n",
      " 169                     Asia     4.748         8    52        668.510\n",
      "   3               Bangladesh     6.500         9    16        340.821\n",
      "  31                     Asia     4.234        10    71        418.716\n",
      " 124                    Egypt     5.956        11    25         61.402\n",
      " 166                   Africa     8.437        12     9     14,722.840\n",
      "   4                  Myanmar     4.972        13    49         15.193\n",
      "  46                     Asia     6.042        14    21        719.537\n",
      " 148 Taiwan Province of China     4.991        15    48         57.706\n",
      " 174                     Asia     2.539        16   140        635.724\n",
      "   5                  Vietnam     1.646        17   161         12.016\n",
      "  40                     Asia     6.890        18    13         13.698\n",
      "  41                  Ireland     2.658        19   136         63.244\n",
      " 146                   Europe     4.639        20    57         68.418\n",
      "   6            Côte d'Ivoire     5.197        21    37         24.448\n",
      " 145                   Africa     4.256        22    70         16.541\n",
      "  34                    China     4.559        23    58         47.354\n",
      " 121                     Asia     1.550        24   162          0.114\n",
      "   7                    Benin     3.500        25   102          7.495\n",
      " 191                   Africa     2.200        26   149          8.488\n",
      "  66                   Turkey     2.477        27   144          0.048\n",
      " 155                   Europe     6.000        28    23          1.913\n",
      "   8               Uzbekistan     3.491        29   104          2.366\n",
      "  52                     Asia     3.770        30    91         49.077\n",
      "  21 Islamic Republic of Iran     7.560        31    10         99.287\n",
      "  31                     Asia     5.690        32    30         10.372\n",
      "   9        Brunei Darussalam     1.496        33   164        262.799\n"
     ]
    }
   ],
   "source": [
    "print(Stats.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def2f3d",
   "metadata": {},
   "source": [
    "6>Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details: A) Repository title B) Repository description C) Contributors count D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26a1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "#Opening the github website\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68269e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on the Explore drop down options\n",
    "explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46aac539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on \"Trending\" option\n",
    "trending=driver.find_element_by_xpath('//ul[@class=\"list-style-none mb-3\"]/li')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a67d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on \"Trending\" option through dropdown options of Explore button\n",
    "driver.find_element_by_xpath('//div[@class=\"d-flex flex-wrap flex-items-center flex-justify-center flex-md-justify-start text-center text-md-left\"]/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3f909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the titles of each repository\n",
    "title = driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "\n",
    "# Making list named \"Title\" and appending all the titles into it\n",
    "Title=[]\n",
    "for i in title:\n",
    "    Title.append(i.text)\n",
    "\n",
    "# Scraping the description of each repository\n",
    "desc=driver.find_elements_by_xpath(\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "# Making list named \"Desc\" and appending all the descriptions into it\n",
    "Desc=[]\n",
    "for i in desc:\n",
    "    if i.text is None :\n",
    "        Desc.append(\"-\") \n",
    "    else:\n",
    "        Desc.append(i.text)\n",
    "# Scraping the contributors of each repository        \n",
    "cont=driver.find_elements_by_xpath(\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "# Making list named \"Contributors\" and appending all the contributors count into it\n",
    "Contributors=[]\n",
    "for i in cont:\n",
    "    if i.text is None :\n",
    "        Contributors.append(\"-\") \n",
    "    else:\n",
    "        Contributors.append(i.text)\n",
    "# Scraping the programming languages of each repository        \n",
    "lang = driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "# Making list named \"Language\" and appending all the languages into it\n",
    "Language=[]    \n",
    "for i in lang:\n",
    "    if i.text is None :\n",
    "        Language.append(\"-\") \n",
    "    else:\n",
    "        Language.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf75ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 22 25 24\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of each list\n",
    "print(len(Title),len(Desc),len(Contributors),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddbc887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bndw / wifi-card</td>\n",
       "      <td>📶 Print a QR code for connecting to your WiFi</td>\n",
       "      <td>125</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook / folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>4,146</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft / IoT-For-Beginners</td>\n",
       "      <td>12 Weeks, 24 Lessons, IoT for All!</td>\n",
       "      <td>300</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NationalSecurityAgency / ghidra</td>\n",
       "      <td>Ghidra is a software reverse engineering (SRE)...</td>\n",
       "      <td>3,619</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / CBL-Mariner</td>\n",
       "      <td>Linux OS for Azure 1P services and edge applia...</td>\n",
       "      <td>89</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opensearch-project / OpenSearch</td>\n",
       "      <td>Open source distributed and RESTful search eng...</td>\n",
       "      <td>255</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avelino / awesome-go</td>\n",
       "      <td>A curated list of awesome Go frameworks, libra...</td>\n",
       "      <td>8,659</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fenixsoft / awesome-fenix</td>\n",
       "      <td>讨论如何构建一套可靠的大型分布式系统</td>\n",
       "      <td>225</td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dromara / Sa-Token</td>\n",
       "      <td>这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...</td>\n",
       "      <td>784</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0vercl0k / wtf</td>\n",
       "      <td>wtf is a distributed, code-coverage guided, cu...</td>\n",
       "      <td>25</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TencentARC / GFPGAN</td>\n",
       "      <td>12 weeks, 24 lessons, classic Machine Learning...</td>\n",
       "      <td>82</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>microsoft / ML-For-Beginners</td>\n",
       "      <td>专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！</td>\n",
       "      <td>2,669</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chefyuan / algorithm-base</td>\n",
       "      <td>End-to-end image segmentation kit based on Pad...</td>\n",
       "      <td>1,134</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PaddlePaddle / PaddleSeg</td>\n",
       "      <td>微信消息解密工具</td>\n",
       "      <td>443</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JustYoomoon / WechatDecrypt</td>\n",
       "      <td> Now we have become very big, Different from ...</td>\n",
       "      <td>35</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jaywcjlove / awesome-mac</td>\n",
       "      <td>🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...</td>\n",
       "      <td>4,834</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kon9chunkit / GitHub-Chinese-Top-Charts</td>\n",
       "      <td>Used to integrate the Facebook Platform with y...</td>\n",
       "      <td>5,142</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>facebook / facebook-ios-sdk</td>\n",
       "      <td>A Go framework for microservices.</td>\n",
       "      <td>2,860</td>\n",
       "      <td>Objective-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>go-kratos / kratos</td>\n",
       "      <td>A cat(1) clone with wings.</td>\n",
       "      <td>2,808</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sharkdp / bat</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>720</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aaron-lv / sync</td>\n",
       "      <td>Model parallel transformers in JAX and Haiku</td>\n",
       "      <td>44</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AkashSingh3031 / The-Complete-FAANG-Preparation</td>\n",
       "      <td>An open source vector database powered by Fais...</td>\n",
       "      <td>569</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  \\\n",
       "0                                  bndw / wifi-card   \n",
       "1                                  facebook / folly   \n",
       "2                     microsoft / IoT-For-Beginners   \n",
       "3                   NationalSecurityAgency / ghidra   \n",
       "4                           microsoft / CBL-Mariner   \n",
       "5                   opensearch-project / OpenSearch   \n",
       "6                              avelino / awesome-go   \n",
       "7                         fenixsoft / awesome-fenix   \n",
       "8                                dromara / Sa-Token   \n",
       "9                                    0vercl0k / wtf   \n",
       "10                              TencentARC / GFPGAN   \n",
       "11                     microsoft / ML-For-Beginners   \n",
       "12                        chefyuan / algorithm-base   \n",
       "13                         PaddlePaddle / PaddleSeg   \n",
       "14                      JustYoomoon / WechatDecrypt   \n",
       "15                         jaywcjlove / awesome-mac   \n",
       "16          kon9chunkit / GitHub-Chinese-Top-Charts   \n",
       "17                      facebook / facebook-ios-sdk   \n",
       "18                               go-kratos / kratos   \n",
       "19                                    sharkdp / bat   \n",
       "20                                  Aaron-lv / sync   \n",
       "21  AkashSingh3031 / The-Complete-FAANG-Preparation   \n",
       "\n",
       "                                                 Desc Contributors Count  \\\n",
       "0       📶 Print a QR code for connecting to your WiFi                125   \n",
       "1   An open-source C++ library developed and used ...              4,146   \n",
       "2                  12 Weeks, 24 Lessons, IoT for All!                300   \n",
       "3   Ghidra is a software reverse engineering (SRE)...              3,619   \n",
       "4   Linux OS for Azure 1P services and edge applia...                 89   \n",
       "5   Open source distributed and RESTful search eng...                255   \n",
       "6   A curated list of awesome Go frameworks, libra...              8,659   \n",
       "7                                  讨论如何构建一套可靠的大型分布式系统                225   \n",
       "8   这可能是史上功能最全的Java权限认证框架！目前已集成——登录认证、权限认证、分布式Sess...                784   \n",
       "9   wtf is a distributed, code-coverage guided, cu...                 25   \n",
       "10  12 weeks, 24 lessons, classic Machine Learning...                 82   \n",
       "11   专门为刚开始刷题的同学准备的算法基地，没有最细只有更细，立志用动画将晦涩难懂的算法说的通俗易懂！              2,669   \n",
       "12  End-to-end image segmentation kit based on Pad...              1,134   \n",
       "13                                           微信消息解密工具                443   \n",
       "14   Now we have become very big, Different from ...                 35   \n",
       "15  🇨🇳 GitHub中文排行榜，帮助你发现高分优秀中文项目、更高效地吸收国人的优秀经验成果；榜...              4,834   \n",
       "16  Used to integrate the Facebook Platform with y...              5,142   \n",
       "17                  A Go framework for microservices.              2,860   \n",
       "18                         A cat(1) clone with wings.              2,808   \n",
       "19  This repository contains all the DSA (Data-Str...                720   \n",
       "20       Model parallel transformers in JAX and Haiku                 44   \n",
       "21  An open source vector database powered by Fais...                569   \n",
       "\n",
       "            Language  \n",
       "0         JavaScript  \n",
       "1                C++  \n",
       "2                C++  \n",
       "3               Java  \n",
       "4                 Go  \n",
       "5               Java  \n",
       "6                 Go  \n",
       "7                Vue  \n",
       "8               Java  \n",
       "9                C++  \n",
       "10            Python  \n",
       "11  Jupyter Notebook  \n",
       "12              Java  \n",
       "13            Python  \n",
       "14               C++  \n",
       "15        JavaScript  \n",
       "16              Java  \n",
       "17       Objective-C  \n",
       "18                Go  \n",
       "19              Rust  \n",
       "20  Jupyter Notebook  \n",
       "21            Python  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame(GitHub)\n",
    "GitHub=pd.DataFrame({})\n",
    "GitHub['Title']=Title[:22]\n",
    "GitHub['Desc']=Desc[:22]\n",
    "GitHub['Contributors Count']=Contributors[:22]\n",
    "GitHub['Language']=Language[:22]\n",
    "#Viewing the DataFrame\n",
    "GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604b870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75eebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e9a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0bce734",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ca1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "#Opening the billboard website\n",
    "driver.get(\"https://www.billboard.com/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04661bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57b69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Charts\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/header/div/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593aa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b82c181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Hot 100\n",
    "driver.find_element_by_xpath('//div[@class=\"charts-landing__info--view-chart-holder\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d4f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the song name by passing xpath\n",
    "song= driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]')\n",
    "\n",
    "#Making a list and storing all the scraped data into it\n",
    "Song=[]\n",
    "for i in song:\n",
    "    if i.text is None :\n",
    "        Song.append(\"-\")\n",
    "    else:\n",
    "        Song.append(i.text)\n",
    "        \n",
    "#Scraping the artist name by passing xpath\n",
    "artist=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "\n",
    "#Making a list and storing all the scraped data into it\n",
    "Artist=[]\n",
    "for i in artist:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"-\")\n",
    "    else:\n",
    "        Artist.append(i.text)\n",
    "        \n",
    "#Scraping the last week rank by passing xpath\n",
    "last_week = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "\n",
    "#Making a list and storing all the scraped data into it\n",
    "Last_week=[]\n",
    "for i in last_week:\n",
    "    if i.text is None :\n",
    "        Last_week.append(\"-\")\n",
    "    else:   \n",
    "        Last_week.append(i.text)\n",
    "        \n",
    "#Scraping the peak rank by passing xpath\n",
    "peak = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "\n",
    "#Making a list and storing all the scraped data into it\n",
    "Peak=[]\n",
    "for i in peak:\n",
    "    if i.text is None :\n",
    "        Peak.append(\"-\")\n",
    "    else:\n",
    "        Peak.append(i.text)\n",
    "        \n",
    "#Scraping the weeks on board by passing xpath\n",
    "weeks_on_board = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "#Making a list and storing all the scraped data into it\n",
    "Weeks_on_Board=[]\n",
    "for i in weeks_on_board:\n",
    "    if i.text is None :\n",
    "        Weeks_on_Board.append(\"-\")\n",
    "    else:\n",
    "        Weeks_on_Board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c264659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of each list\n",
    "print(len(Song),len(Artist),len(Last_week),len(Peak),len(Weeks_on_Board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c16af34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montero (Call Me By Your Name)</td>\n",
       "      <td>Lil Nas X</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>What's Next</td>\n",
       "      <td>Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Enough For You</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Juggernaut</td>\n",
       "      <td>Tyler, The Creator Featuring Lil Uzi Vert &amp; Ph...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tell Em</td>\n",
       "      <td>Cochise &amp; $NOT</td>\n",
       "      <td>-</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song name  \\\n",
       "0                           Butter   \n",
       "1                         Good 4 U   \n",
       "2                       Levitating   \n",
       "3                     Kiss Me More   \n",
       "4   Montero (Call Me By Your Name)   \n",
       "..                             ...   \n",
       "95               All I Know So Far   \n",
       "96                     What's Next   \n",
       "97                  Enough For You   \n",
       "98                      Juggernaut   \n",
       "99                         Tell Em   \n",
       "\n",
       "                                          Artist name Last week rank  \\\n",
       "0                                                 BTS              1   \n",
       "1                                      Olivia Rodrigo              2   \n",
       "2                           Dua Lipa Featuring DaBaby              4   \n",
       "3                              Doja Cat Featuring SZA              3   \n",
       "4                                           Lil Nas X              8   \n",
       "..                                                ...            ...   \n",
       "95                                               P!nk              -   \n",
       "96                                              Drake              -   \n",
       "97                                     Olivia Rodrigo              -   \n",
       "98  Tyler, The Creator Featuring Lil Uzi Vert & Ph...             40   \n",
       "99                                     Cochise & $NOT              -   \n",
       "\n",
       "   Peak rank Weeks on Board  \n",
       "0          1              7  \n",
       "1          1              8  \n",
       "2          2             40  \n",
       "3          3             13  \n",
       "4          1             15  \n",
       "..       ...            ...  \n",
       "95        74              4  \n",
       "96         1             16  \n",
       "97        14              6  \n",
       "98        40              2  \n",
       "99        64              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame(Billboard)\n",
    "Billboard=pd.DataFrame({})\n",
    "Billboard['Song name']=Song \n",
    "Billboard['Artist name']=Artist \n",
    "Billboard['Last week rank']=Last_week \n",
    "Billboard['Peak rank']=Peak\n",
    "Billboard['Weeks on Board']=Weeks_on_Board\n",
    "#Viewing the DataFrame\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ac9bc",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/ You have to find the following details: A) Name B) Designation C) Company D) Skills they hire for E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7d75885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "#Opening the naukri website\n",
    "driver.get(\"https://www.naukri.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6da17b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Recruiters\n",
    "driver.find_element_by_xpath('//a[@ data-ga-track=\"Main Navigation Recruiters|Recruiters Icon\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3cbe8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.naukri.com/hr-recruiters-consultants\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d1b4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_bar = driver.find_element_by_xpath('//input[@ class=\"sugInp\"]')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "472fe34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17368694",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_botton=driver.find_element_by_xpath('//button[@type=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d1ad0b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tanushree',\n",
       " 'sashi bhushan',\n",
       " 'Bitapi',\n",
       " 'Gajendra Singh',\n",
       " 'Sadashiv Kulkarni',\n",
       " 'Invelopment',\n",
       " 'Anjali Srivastava',\n",
       " 'Anoop Somarajan',\n",
       " 'Helly Vyas',\n",
       " 'Ashish Verma',\n",
       " 'Bhuwneshari Devi',\n",
       " 'HS Sandesh',\n",
       " 'Datafoundry',\n",
       " 'A Valsa Florina',\n",
       " 'Kalaivani M V',\n",
       " 'Prashant K',\n",
       " 'Radhika',\n",
       " 'Rakhi',\n",
       " 'Monika Jain',\n",
       " 'Trilok Nath',\n",
       " 'Sridharan',\n",
       " 'Rashmi Kathuria',\n",
       " 'Vidya Rani Hadimani',\n",
       " 'Monika Singh Thakur',\n",
       " 'Shikha Bakshi',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Jayanth N',\n",
       " 'Ishu Kumar',\n",
       " 'Ravi',\n",
       " 'Vivek Shrivastava',\n",
       " 'Gayathri E',\n",
       " 'Best In Town Analytics',\n",
       " 'Santhosh Nagaiah',\n",
       " 'priyanka',\n",
       " 'Renny Benita K',\n",
       " 'Roshan Menugu',\n",
       " 'HR Team',\n",
       " 'Jamil Akhtar',\n",
       " 'rajesh',\n",
       " 'navya neluri',\n",
       " 'Ram Kumar',\n",
       " 'Vanitha Senkurichi',\n",
       " 'Sravan Kumar Ranga',\n",
       " 'Prachi Naware',\n",
       " 'Arya',\n",
       " 'Blueberry Digital Labs',\n",
       " 'Shiva Kumar N',\n",
       " 'Ms Uma',\n",
       " 'Manoj Kumar Ganesh',\n",
       " 'Kranthi Kumar M']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]'):\n",
    "\n",
    "   name2.append(i.text.replace('\\n',''))\n",
    "name2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7a94192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead Recruiter',\n",
       " 'Senior Specialist',\n",
       " 'HR and Operation Manager',\n",
       " 'Head of Recruitment - Product &amp;...',\n",
       " 'Company HR',\n",
       " 'Company HR',\n",
       " 'Director HR',\n",
       " 'Assistant Manager Talent Acquisition',\n",
       " 'HR Business Partner',\n",
       " 'Senior Associate Human Resources',\n",
       " 'Lead Talent Acquisition',\n",
       " 'Talent Evangelist www staffiohr co',\n",
       " 'Company HR',\n",
       " 'Recruitment Specialist',\n",
       " 'HR Manager',\n",
       " 'Sr HR',\n",
       " 'HR Associate',\n",
       " 'HR recruiter',\n",
       " 'Talent Aquistion Lead',\n",
       " 'Senior IT Recruiter',\n",
       " 'Company Recruiter Vice President',\n",
       " 'Talent Acquisition Specialist (Specialized...',\n",
       " 'Business Manager Delivery',\n",
       " 'Technical Recruiter',\n",
       " 'Senior Manager Recruitment',\n",
       " 'Recruitment Lead Consultant',\n",
       " 'Project Manager',\n",
       " 'Co Founder &amp; Ceo',\n",
       " 'Team HR',\n",
       " 'Assistant Manager Human Resources',\n",
       " 'Sr Recruitment',\n",
       " 'Analytics Associate',\n",
       " 'Chief marketing officer',\n",
       " 'General Manager',\n",
       " 'Operations Manager',\n",
       " 'Company Recruiter',\n",
       " 'Company HR',\n",
       " 'Company Recruiter',\n",
       " 'HR Executive',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Company HR',\n",
       " 'Assistant Manager',\n",
       " 'Recruitment Executive',\n",
       " 'Human Resources Manager',\n",
       " 'HR',\n",
       " 'Founder',\n",
       " 'Company HR',\n",
       " 'Senior HR Associate',\n",
       " 'Lead HR Talent Acquisition']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designation=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]'):\n",
    "\n",
    "   designation.append(i.text.replace('\\n',''))\n",
    "designation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df87745c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Noida',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'Noida',\n",
       " 'Chennai',\n",
       " 'Pune',\n",
       " 'Gurgaon',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Chennai',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Coimbatore',\n",
       " 'Singapore - (singapore)',\n",
       " 'Noida',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Chennai',\n",
       " 'Noida',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Indore',\n",
       " 'Gurgaon',\n",
       " 'Vadodara / Baroda',\n",
       " 'Mysoru / Mysore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Ghaziabad',\n",
       " 'Noida',\n",
       " 'Chennai',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Navi Mumbai',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Noida',\n",
       " 'Chennai',\n",
       " 'Hyderabad / Secunderabad']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//small[@class=\"ellipsis\"]'):\n",
    "\n",
    "   loc.append(i.text.replace('\\n',''))\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "020beab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tanushree',\n",
       " 'RecRoots',\n",
       " 'sashi bhushan',\n",
       " 'Wipro',\n",
       " 'Bitapi',\n",
       " 'Anvaya',\n",
       " 'Gajendra Singh',\n",
       " 'A Leading of Product Start-UP Company',\n",
       " 'Sadashiv Kulkarni',\n",
       " 'Digitially Insights Pvt Ltd',\n",
       " 'Invelopment',\n",
       " 'Invelopment',\n",
       " 'Anjali Srivastava',\n",
       " 'CodeFire Technologies Pvt. Ltd.',\n",
       " 'Anoop Somarajan',\n",
       " 'Access Healthcare',\n",
       " 'Helly Vyas',\n",
       " 'AM - TA &amp; HR',\n",
       " 'Ashish Verma',\n",
       " 'Evalueserve.com Private Limited',\n",
       " 'Bhuwneshari Devi',\n",
       " 'Success Pact Consulting',\n",
       " 'HS Sandesh',\n",
       " 'Staffio HR',\n",
       " 'Datafoundry',\n",
       " 'JAITRA SOFTWARE SOLUTIONS PVT LTD',\n",
       " 'A Valsa Florina',\n",
       " 'Redbus.in',\n",
       " 'Kalaivani M V',\n",
       " 'ZYUDLY LABS DATA SOLUTIONS PRIVATE LIMITED',\n",
       " 'Prashant K',\n",
       " 'Confidential',\n",
       " 'Radhika',\n",
       " 'Bright Bridge Info-tech Pvt Ltd',\n",
       " 'Rakhi',\n",
       " 'Constalytics',\n",
       " 'Monika Jain',\n",
       " 'Info Edge India Limited',\n",
       " 'Trilok Nath',\n",
       " 'Molveno Consulting Private Limited',\n",
       " 'Sridharan',\n",
       " 'Aaum Research and Analytics Private Limited',\n",
       " 'Rashmi Kathuria',\n",
       " 'Mount Talent consulting',\n",
       " 'Vidya Rani Hadimani',\n",
       " 'Talent Management Labs Inc.',\n",
       " 'Monika Singh Thakur',\n",
       " 'ValueLabs',\n",
       " 'Shikha Bakshi',\n",
       " 'Fractal Analytics!!',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Apidel Technologies Division of Transpower',\n",
       " 'Jayanth N',\n",
       " 'Dollarbird Information Services Pvt, Ltd',\n",
       " 'Ishu Kumar',\n",
       " 'Data X',\n",
       " 'Ravi',\n",
       " 'Einfluss Teknocommercial Pvt. Ltd.',\n",
       " 'Vivek Shrivastava',\n",
       " 'InnovAccer Management Pvt Ltd',\n",
       " 'Gayathri E',\n",
       " 'Wonderwrks IT Services Private Limited',\n",
       " 'Best In Town Analytics',\n",
       " 'BITA',\n",
       " 'Santhosh Nagaiah',\n",
       " 'Tuple Technologies Pte Ltd',\n",
       " 'priyanka',\n",
       " 'Reliance Industries',\n",
       " 'Renny Benita K',\n",
       " 'DeepIQ Software Solutions Pvt Ltd',\n",
       " 'Roshan Menugu',\n",
       " 'Cyient Limited',\n",
       " 'HR Team',\n",
       " 'Terra Blue Exploration Technologies Pvt....',\n",
       " 'Jamil Akhtar',\n",
       " 'Quikkloan',\n",
       " 'rajesh',\n",
       " 'quantum value IT services',\n",
       " 'navya neluri',\n",
       " 'asens labs',\n",
       " 'Ram Kumar',\n",
       " 'Working As A Freelancer',\n",
       " 'Vanitha Senkurichi',\n",
       " 'Quaero 3 India Ltd',\n",
       " 'Sravan Kumar Ranga',\n",
       " 'GSPANN Technologies',\n",
       " 'Prachi Naware',\n",
       " 'TechnoSpan Technologies',\n",
       " 'Arya',\n",
       " 'Arya.ai',\n",
       " 'Blueberry Digital Labs',\n",
       " 'Blueberry Digital Labs',\n",
       " 'Shiva Kumar N',\n",
       " 'Rapid Talent Solutions -9148242334',\n",
       " 'Ms Uma',\n",
       " 'RenovITe Payment Solutions Pvt ltd',\n",
       " 'Manoj Kumar Ganesh',\n",
       " 'Cads Software India',\n",
       " 'Kranthi Kumar M',\n",
       " 'PrimEra Medical Technologies Private...']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organization=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"ellipsis\"]'):\n",
    "\n",
    "   organization.append(i.text.replace('\\n',''))\n",
    "organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f3b0b6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UI Developers, Software Engineers, Quality Assurance, Principal Engineers, Data Scientists, Product Manager, Android Developer, Web Developer, Design, coding',\n",
       " 'pig, hbase, sas, spss, apache, python, nosql, php, Cloud Computing, hadoop, r, Hadoop Architect, spark, flume, Advanced Excel, statistics',\n",
       " 'Hadoop, Big Data, Data Scientists, Java, Spring Boot, Oracle, SQL, MySQL, Object Oriented Programming, RDBMS, Data Modeling',\n",
       " 'Data Scientist, Big Data, Hadoop, Web Analytics, NLP, Machine Learning, J2EE, SAP, Oracle, ERP, .Net, Sharepoint, Architecture, Devops, Mobile APPs',\n",
       " 'Big Data Engineer, Data Scientist, Solutions, Test Cases, Big Data, Developer, Hadoop, Analytics, Data Analytics, Predictive Modeling',\n",
       " 'Scandinavian Startups',\n",
       " 'Technical, Business Development Executive, Software Developer, Technical Lead, Project Manager, Business Development Manager, Business Head, Php Developer',\n",
       " 'Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript, Css, Github, Data Scientist, Machine Learning, R, Angularjs, Node.js, Aws, Web Development, Sql Dba',\n",
       " 'Big Data technology, PLSQL, Web Developer, Java, Data Scientist, Financial Analyst, Investment Banking, Big Data packages/applications, Scala, Python, Impala',\n",
       " 'SAS, VBA, Business Information Services(BIS), Legal, Corporate Lawyers, Business Research, Library Services, Natural Language Processing (NLP), Industry',\n",
       " 'Amazon, Olacabs, Quikr, Bankbazzar, Uber, Flipkart, Treebo, Shuttl, Rivigo, BrowserStack, Crowdfire, Mindtickle, Hike, Igniteworld',\n",
       " 'Digital Marketing, General Manager, Business Development, Product Manager, Big Data, Business Analyst, Frontend Developer, Human Resources, data',\n",
       " 'Webmethods Developer, Mean Stack, Business Analysis, Data Scientist, Database Development, java, python, Algorithm Scientist, Machine Learning, artificial',\n",
       " 'Business Analyst, Front end developer, legal, Finance Manager, Global Gds, Product Manager, SEO Specialist, Big Data, sales and business development, L2',\n",
       " 'Data Scientist, Cloud Computing, Mobile Application Development',\n",
       " 'Data Analyst, Statistical Analysis, Data Scientist, Analytics Manager, Software Engineer',\n",
       " 'business analyst - IT (python), pay per click, social media marketing, retargeting on videos, Online Branding Professional, Data Scientist, Post-sales',\n",
       " 'Data Scientist, Data Research Analyst, Big Data, Analytics, Data Modelling And Mapping, Graph Database',\n",
       " 'Lamp Developer, Ui/ux Developer, Qa Engineer, Java Developer, Data Scientist',\n",
       " '.Net Developers With Angular Js, Html, Front End Developers With React Js, Node Js Developer, Landesk Admin, Help Desk Admin, Sfdc, Sfdc Consutant, Data',\n",
       " 'Data Scientist, Developer, Ui, Accounting',\n",
       " 'Leading MNCs, Product based organizations',\n",
       " 'Amazon Walmart Adobe OLA Myntracom Komli Media Practo Showt RevX DataRPM Adobe Infoworks PayPal Elasticbeam Appdynamics Cloodon fashalot Curefit kensci Soroco',\n",
       " 'Big Data Analytics, Marketing Analytics, Full Stack, Technical Architecture',\n",
       " 'Analytics, Big Data, Hadoop, Python',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       " 'Python, Machine Learning, Sql, Data Science',\n",
       " 'Deep Learning, Machine Learning, unstructured data mining, natural language processing, Artificial Intelligence, Pattern Recognition, Information Retrieval',\n",
       " 'Business Analyst, analytics, Decesion Scientist, Data Scientist, Developer, Machine Learning, NLP, Machine Linguistics, Product Development',\n",
       " 'IT Infrastructure Management, PHP, Wordpress, MySQL, Java, IPTABLES, Coldfusion, Debian, Bash, SQL, Ubuntu, Networking, UI Development, HTML, Javascript',\n",
       " 'Data Analytics',\n",
       " 'Data Science, Project Management, Backend',\n",
       " 'Sap, Saas, Sql, Hadoop, Production Planning, Business Development, Software Development, Project Management, Big Data, Data Analytics, Data Science',\n",
       " 'Core Java, J2ee, Big Data, Machine Learning, Deep Learning, Real Time Analysis, Ui, Front End',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Data Scientist, Tableau, R Tool, Data Analytics, Business Analytics',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'sql, Ui Development, ssis, Data Modeling, Data Warehousing, root cause analysis, Performance Tuning, Database Maintenance, Technical Documentation',\n",
       " 'devops, build and release, Delivery Manager, Oracle Webcenter, selenium, ruby, hadoop, teamsite, java/j2ee, datastage, informatica, Production Support, core',\n",
       " 'Machine Learning, React.js, Computer Vision, Artificial Intelligence, Nlp, Architect, Silicon Valley, Startup, Data Science',\n",
       " 'Artificial Intelligence, Deep Learning, Machine Learning, Data Science, Data Analytics, Data Mining, Python, Enterprise Architecture, Product Management, New',\n",
       " 'Node.js, Html, Css, Nosql, Web Designing, Web Application, Python, Data Analysis, Layout, Desktop Publishing, Seo',\n",
       " 'salaesforce, Web Technologies, .net, .net full stack, java full stack, servicenow, Java, Automation Testing, Front End Developer, Backend Developer, Mobile',\n",
       " 'java, J2ee, activemq, rest, cassandra, redis, nosql, spark, Big Data, scala, cq5, aem, spring, c++, Test Engineering, Performance Testing',\n",
       " 'Java, J2EE, Oracle E-business Suite, MS CRM, Protocol Development, IP/Networking Reqts, Big Data, hadoop, hive, Machine Learning, Data Scientist, R',\n",
       " 'Medical Coders, mbbs, bi, appeals, master data management, Big Data, hadoop, Predictive Analytics, Business Intelligence, managed care organization']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]'):\n",
    "\n",
    "   skill.append(i.text.replace('\\n',''))\n",
    "skill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b0d6de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Location</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanushree</td>\n",
       "      <td>Lead Recruiter</td>\n",
       "      <td>Tanushree</td>\n",
       "      <td>Noida</td>\n",
       "      <td>UI Developers, Software Engineers, Quality Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sashi bhushan</td>\n",
       "      <td>Senior Specialist</td>\n",
       "      <td>RecRoots</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>pig, hbase, sas, spss, apache, python, nosql, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitapi</td>\n",
       "      <td>HR and Operation Manager</td>\n",
       "      <td>sashi bhushan</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Hadoop, Big Data, Data Scientists, Java, Sprin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gajendra Singh</td>\n",
       "      <td>Head of Recruitment - Product &amp;amp;...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Data Scientist, Big Data, Hadoop, Web Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sadashiv Kulkarni</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Bitapi</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Big Data Engineer, Data Scientist, Solutions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Invelopment</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Anvaya</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Scandinavian Startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anjali Srivastava</td>\n",
       "      <td>Director HR</td>\n",
       "      <td>Gajendra Singh</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Technical, Business Development Executive, Sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anoop Somarajan</td>\n",
       "      <td>Assistant Manager Talent Acquisition</td>\n",
       "      <td>A Leading of Product Start-UP Company</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Helly Vyas</td>\n",
       "      <td>HR Business Partner</td>\n",
       "      <td>Sadashiv Kulkarni</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Big Data technology, PLSQL, Web Developer, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ashish Verma</td>\n",
       "      <td>Senior Associate Human Resources</td>\n",
       "      <td>Digitially Insights Pvt Ltd</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SAS, VBA, Business Information Services(BIS), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                             Designation  \\\n",
       "0          Tanushree                          Lead Recruiter   \n",
       "1      sashi bhushan                       Senior Specialist   \n",
       "2             Bitapi                HR and Operation Manager   \n",
       "3     Gajendra Singh  Head of Recruitment - Product &amp;...   \n",
       "4  Sadashiv Kulkarni                              Company HR   \n",
       "5        Invelopment                              Company HR   \n",
       "6  Anjali Srivastava                             Director HR   \n",
       "7    Anoop Somarajan    Assistant Manager Talent Acquisition   \n",
       "8         Helly Vyas                     HR Business Partner   \n",
       "9       Ashish Verma        Senior Associate Human Resources   \n",
       "\n",
       "                            Organization               Location  \\\n",
       "0                              Tanushree                  Noida   \n",
       "1                               RecRoots  Bengaluru / Bangalore   \n",
       "2                          sashi bhushan  Bengaluru / Bangalore   \n",
       "3                                  Wipro                  Noida   \n",
       "4                                 Bitapi                   Pune   \n",
       "5                                 Anvaya              Ahmedabad   \n",
       "6                         Gajendra Singh                  Noida   \n",
       "7  A Leading of Product Start-UP Company                Chennai   \n",
       "8                      Sadashiv Kulkarni                   Pune   \n",
       "9            Digitially Insights Pvt Ltd                Gurgaon   \n",
       "\n",
       "                                               skill  \n",
       "0  UI Developers, Software Engineers, Quality Ass...  \n",
       "1  pig, hbase, sas, spss, apache, python, nosql, ...  \n",
       "2  Hadoop, Big Data, Data Scientists, Java, Sprin...  \n",
       "3  Data Scientist, Big Data, Hadoop, Web Analytic...  \n",
       "4  Big Data Engineer, Data Scientist, Solutions, ...  \n",
       "5                              Scandinavian Startups  \n",
       "6  Technical, Business Development Executive, Sof...  \n",
       "7  Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...  \n",
       "8  Big Data technology, PLSQL, Web Developer, Jav...  \n",
       "9  SAS, VBA, Business Information Services(BIS), ...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame(GitHub)\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name']=name2[:10]\n",
    "Naukri['Designation']=designation[:10]\n",
    "Naukri['Organization']=organization[:10]\n",
    "Naukri['Location']=loc[:10]\n",
    "Naukri['skill']=skill[:10]\n",
    "#Viewing the DataFrame\n",
    "\n",
    "\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83020db6",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e440b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#Clicking on books\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e5885a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the book names\n",
    "book=driver.find_elements_by_xpath('//tr[@class=\"odd\"]/td[2]')\n",
    "\n",
    "Book=[]\n",
    "for i in book:\n",
    "    if i.text is None :\n",
    "        Book.append(\"-\") \n",
    "    else:\n",
    "        Book.append(i.text)\n",
    "# Scraping the author names      \n",
    "author=driver.find_elements_by_xpath('//tr[@class=\"odd\"]/td[3]')\n",
    "\n",
    "Author=[]\n",
    "for i in author:\n",
    "    if i.text is None :\n",
    "        Author.append(\"-\") \n",
    "    else:\n",
    "        Author.append(i.text)\n",
    "# Scraping the volumes        \n",
    "volumes=driver.find_elements_by_xpath('//tr[@class=\"odd\"]/td[4]')\n",
    "\n",
    "Volumes=[]\n",
    "for i in volumes:\n",
    "    if i.text is None :\n",
    "        Volumes.append(\"-\") \n",
    "    else:\n",
    "        Volumes.append(i.text)\n",
    " # Scraping the  publishers       \n",
    "publisher=driver.find_elements_by_xpath('//tr[@class=\"odd\"]/td[5]')\n",
    "\n",
    "Publisher=[]\n",
    "for i in publisher:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"-\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    " # Scraping the genres       \n",
    "genre=driver.find_elements_by_xpath('//tr[@class=\"odd\"]/td[6]')\n",
    "\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"-\") \n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66d16788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,052,876</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Curious Incident of the Dog in the Night-time,The</td>\n",
       "      <td>Haddon, Mark</td>\n",
       "      <td>1,979,552</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Short History of Nearly Everything,A</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>1,852,919</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>1,787,118</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gruffalo,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,781,269</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kite Runner,The</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,629,119</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thousand Splendid Suns,A</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,583,992</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Time Traveler's Wife,The</td>\n",
       "      <td>Niffenegger, Audrey</td>\n",
       "      <td>1,546,886</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bridget Jones's Diary:A Novel</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>1,508,205</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Captain Corelli's Mandolin</td>\n",
       "      <td>Bernieres, Louis de</td>\n",
       "      <td>1,352,318</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Life of Pi</td>\n",
       "      <td>Martel, Yann</td>\n",
       "      <td>1,310,176</td>\n",
       "      <td>Canongate</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Child Called It,A</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>1,217,712</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Angela's Ashes:A Memoir of a Childhood</td>\n",
       "      <td>McCourt, Frank</td>\n",
       "      <td>1,204,058</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Autobiography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Northern Lights:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,181,503</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Harry Potter and the Half-blood Prince</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>1,153,181</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Man and Boy</td>\n",
       "      <td>Parsons, Tony</td>\n",
       "      <td>1,130,802</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>No.1 Ladies' Detective Agency,The:No.1 Ladies'...</td>\n",
       "      <td>McCall Smith, Alexander</td>\n",
       "      <td>1,115,549</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PS, I Love You</td>\n",
       "      <td>Ahern, Cecelia</td>\n",
       "      <td>1,107,379</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shadow of the Wind,The</td>\n",
       "      <td>Zafon, Carlos Ruiz</td>\n",
       "      <td>1,092,349</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Broker,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>1,087,262</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subtle Knife,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,037,160</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Delia's How to Cook:(Bk.1)</td>\n",
       "      <td>Smith, Delia</td>\n",
       "      <td>1,015,956</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Boy in the Striped Pyjamas,The</td>\n",
       "      <td>Boyne, John</td>\n",
       "      <td>1,004,414</td>\n",
       "      <td>Random House Childrens Books G</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amber Spyglass,The:His Dark Materials S.</td>\n",
       "      <td>Pullman, Philip</td>\n",
       "      <td>1,002,314</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Men are from Mars, Women are from Venus:A Prac...</td>\n",
       "      <td>Gray, John</td>\n",
       "      <td>992,846</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Popular Culture &amp; Media: General Interest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Short History of Tractors in Ukrainian,A</td>\n",
       "      <td>Lewycka, Marina</td>\n",
       "      <td>986,115</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lord of the Rings,The</td>\n",
       "      <td>Tolkien, J. R. R.</td>\n",
       "      <td>967,466</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Interpretation of Murder,The</td>\n",
       "      <td>Rubenfeld, Jed</td>\n",
       "      <td>962,515</td>\n",
       "      <td>Headline</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Alchemist,The:A Fable About Following Your Dream</td>\n",
       "      <td>Coelho, Paulo</td>\n",
       "      <td>956,114</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Notes from a Small Island</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>931,312</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bridget Jones: The Edge of Reason</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>924,695</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I Can Make You Thin</td>\n",
       "      <td>McKenna, Paul</td>\n",
       "      <td>905,086</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Summons,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>869,671</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Nigella Express</td>\n",
       "      <td>Lawson, Nigella</td>\n",
       "      <td>862,602</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Memory Keeper's Daughter,The</td>\n",
       "      <td>Edwards, Kim</td>\n",
       "      <td>845,858</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>About a Boy</td>\n",
       "      <td>Hornby, Nick</td>\n",
       "      <td>828,215</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>God Delusion,The</td>\n",
       "      <td>Dawkins, Richard</td>\n",
       "      <td>816,907</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>White Teeth</td>\n",
       "      <td>Smith, Zadie</td>\n",
       "      <td>815,586</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Book Thief,The</td>\n",
       "      <td>Zusak, Markus</td>\n",
       "      <td>809,641</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name  \\\n",
       "0                Harry Potter and the Deathly Hallows   \n",
       "1           Harry Potter and the Order of the Phoenix   \n",
       "2                 Harry Potter and the Goblet of Fire   \n",
       "3            Harry Potter and the Prisoner of Azkaban   \n",
       "4   Harry Potter and the Half-blood Prince:Childre...   \n",
       "5                                            Twilight   \n",
       "6                                  Fifty Shades Freed   \n",
       "7                                            New Moon   \n",
       "8                                             Eclipse   \n",
       "9   Curious Incident of the Dog in the Night-time,The   \n",
       "10               Short History of Nearly Everything,A   \n",
       "11                                      Breaking Dawn   \n",
       "12                                       Gruffalo,The   \n",
       "13                                    Kite Runner,The   \n",
       "14                           Thousand Splendid Suns,A   \n",
       "15                           Time Traveler's Wife,The   \n",
       "16                      Bridget Jones's Diary:A Novel   \n",
       "17                         Captain Corelli's Mandolin   \n",
       "18                                         Life of Pi   \n",
       "19                                  Child Called It,A   \n",
       "20             Angela's Ashes:A Memoir of a Childhood   \n",
       "21              Northern Lights:His Dark Materials S.   \n",
       "22             Harry Potter and the Half-blood Prince   \n",
       "23                                        Man and Boy   \n",
       "24  No.1 Ladies' Detective Agency,The:No.1 Ladies'...   \n",
       "25                                     PS, I Love You   \n",
       "26                             Shadow of the Wind,The   \n",
       "27                                         Broker,The   \n",
       "28             Subtle Knife,The:His Dark Materials S.   \n",
       "29                         Delia's How to Cook:(Bk.1)   \n",
       "30                     Boy in the Striped Pyjamas,The   \n",
       "31           Amber Spyglass,The:His Dark Materials S.   \n",
       "32  Men are from Mars, Women are from Venus:A Prac...   \n",
       "33           Short History of Tractors in Ukrainian,A   \n",
       "34                              Lord of the Rings,The   \n",
       "35                       Interpretation of Murder,The   \n",
       "36   Alchemist,The:A Fable About Following Your Dream   \n",
       "37                          Notes from a Small Island   \n",
       "38                  Bridget Jones: The Edge of Reason   \n",
       "39                                I Can Make You Thin   \n",
       "40                                        Summons,The   \n",
       "41                                    Nigella Express   \n",
       "42                       Memory Keeper's Daughter,The   \n",
       "43                                        About a Boy   \n",
       "44                                   God Delusion,The   \n",
       "45                                        White Teeth   \n",
       "46                                     Book Thief,The   \n",
       "47                                          Ghost,The   \n",
       "48              Hunger Games,The:Hunger Games Trilogy   \n",
       "49  Jamie's Ministry of Food:Anyone Can Learn to C...   \n",
       "\n",
       "                Author Name Volumes sold                       Publisher  \\\n",
       "0             Rowling, J.K.    4,475,152                      Bloomsbury   \n",
       "1             Rowling, J.K.    4,179,479                      Bloomsbury   \n",
       "2             Rowling, J.K.    3,583,215                      Bloomsbury   \n",
       "3             Rowling, J.K.    3,377,906                      Bloomsbury   \n",
       "4             Rowling, J.K.    2,950,264                      Bloomsbury   \n",
       "5          Meyer, Stephenie    2,315,405              Little, Brown Book   \n",
       "6              James, E. L.    2,193,928                    Random House   \n",
       "7          Meyer, Stephenie    2,152,737              Little, Brown Book   \n",
       "8          Meyer, Stephenie    2,052,876              Little, Brown Book   \n",
       "9              Haddon, Mark    1,979,552                    Random House   \n",
       "10             Bryson, Bill    1,852,919                      Transworld   \n",
       "11         Meyer, Stephenie    1,787,118              Little, Brown Book   \n",
       "12         Donaldson, Julia    1,781,269                   Pan Macmillan   \n",
       "13         Hosseini, Khaled    1,629,119                      Bloomsbury   \n",
       "14         Hosseini, Khaled    1,583,992                      Bloomsbury   \n",
       "15      Niffenegger, Audrey    1,546,886                    Random House   \n",
       "16          Fielding, Helen    1,508,205                   Pan Macmillan   \n",
       "17      Bernieres, Louis de    1,352,318                    Random House   \n",
       "18             Martel, Yann    1,310,176                       Canongate   \n",
       "19             Pelzer, Dave    1,217,712                           Orion   \n",
       "20           McCourt, Frank    1,204,058                   HarperCollins   \n",
       "21          Pullman, Philip    1,181,503                 Scholastic Ltd.   \n",
       "22            Rowling, J.K.    1,153,181                      Bloomsbury   \n",
       "23            Parsons, Tony    1,130,802                   HarperCollins   \n",
       "24  McCall Smith, Alexander    1,115,549              Little, Brown Book   \n",
       "25           Ahern, Cecelia    1,107,379                   HarperCollins   \n",
       "26       Zafon, Carlos Ruiz    1,092,349                           Orion   \n",
       "27            Grisham, John    1,087,262                    Random House   \n",
       "28          Pullman, Philip    1,037,160                 Scholastic Ltd.   \n",
       "29             Smith, Delia    1,015,956                    Random House   \n",
       "30              Boyne, John    1,004,414  Random House Childrens Books G   \n",
       "31          Pullman, Philip    1,002,314                 Scholastic Ltd.   \n",
       "32               Gray, John      992,846                   HarperCollins   \n",
       "33          Lewycka, Marina      986,115                         Penguin   \n",
       "34        Tolkien, J. R. R.      967,466                   HarperCollins   \n",
       "35           Rubenfeld, Jed      962,515                        Headline   \n",
       "36            Coelho, Paulo      956,114                   HarperCollins   \n",
       "37             Bryson, Bill      931,312                      Transworld   \n",
       "38          Fielding, Helen      924,695                   Pan Macmillan   \n",
       "39            McKenna, Paul      905,086                      Transworld   \n",
       "40            Grisham, John      869,671                    Random House   \n",
       "41          Lawson, Nigella      862,602                    Random House   \n",
       "42             Edwards, Kim      845,858                         Penguin   \n",
       "43             Hornby, Nick      828,215                         Penguin   \n",
       "44         Dawkins, Richard      816,907                      Transworld   \n",
       "45             Smith, Zadie      815,586                         Penguin   \n",
       "46            Zusak, Markus      809,641                      Transworld   \n",
       "47           Harris, Robert      807,311                    Random House   \n",
       "48         Collins, Suzanne      792,187                 Scholastic Ltd.   \n",
       "49            Oliver, Jamie      791,095                         Penguin   \n",
       "\n",
       "                                        Genre  \n",
       "0                          Children's Fiction  \n",
       "1                          Children's Fiction  \n",
       "2                          Children's Fiction  \n",
       "3                          Children's Fiction  \n",
       "4                          Children's Fiction  \n",
       "5                         Young Adult Fiction  \n",
       "6                             Romance & Sagas  \n",
       "7                         Young Adult Fiction  \n",
       "8                         Young Adult Fiction  \n",
       "9                  General & Literary Fiction  \n",
       "10                            Popular Science  \n",
       "11                        Young Adult Fiction  \n",
       "12                              Picture Books  \n",
       "13                 General & Literary Fiction  \n",
       "14                 General & Literary Fiction  \n",
       "15                 General & Literary Fiction  \n",
       "16                 General & Literary Fiction  \n",
       "17                 General & Literary Fiction  \n",
       "18                 General & Literary Fiction  \n",
       "19                     Autobiography: General  \n",
       "20                     Autobiography: General  \n",
       "21                        Young Adult Fiction  \n",
       "22                  Science Fiction & Fantasy  \n",
       "23                 General & Literary Fiction  \n",
       "24                Crime, Thriller & Adventure  \n",
       "25                 General & Literary Fiction  \n",
       "26                 General & Literary Fiction  \n",
       "27                Crime, Thriller & Adventure  \n",
       "28                        Young Adult Fiction  \n",
       "29                      Food & Drink: General  \n",
       "30                        Young Adult Fiction  \n",
       "31                        Young Adult Fiction  \n",
       "32  Popular Culture & Media: General Interest  \n",
       "33                 General & Literary Fiction  \n",
       "34                  Science Fiction & Fantasy  \n",
       "35                Crime, Thriller & Adventure  \n",
       "36                 General & Literary Fiction  \n",
       "37                             Travel Writing  \n",
       "38                 General & Literary Fiction  \n",
       "39                             Fitness & Diet  \n",
       "40                Crime, Thriller & Adventure  \n",
       "41                      Food & Drink: General  \n",
       "42                 General & Literary Fiction  \n",
       "43                 General & Literary Fiction  \n",
       "44                            Popular Science  \n",
       "45                 General & Literary Fiction  \n",
       "46                 General & Literary Fiction  \n",
       "47                 General & Literary Fiction  \n",
       "48                        Young Adult Fiction  \n",
       "49                      Food & Drink: General  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name']=Book\n",
    "Novels['Author Name']=Author\n",
    "Novels['Volumes sold']=Volumes\n",
    "Novels['Publisher']=Publisher\n",
    "Novels['Genre']=Genre \n",
    "#Viewing the DataFrame\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f43d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "# Opening the IMDB website\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a042114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the title of the webseries\n",
    "title=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "# Scraping the year span of the webseries\n",
    "year=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "# Scraping the genre of the webseries\n",
    "genre=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "# Scraping the runtime of the webseries\n",
    "runtime = driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "# Scraping the tratings of the webseries\n",
    "ratings=driver.find_elements_by_xpath('//div[@class=\"ipl-rating-widget\"]/div[1]')\n",
    "# Scraping the votes of the webseries\n",
    "votes=driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "\n",
    "#Making a list and storing all the scraped titles into it\n",
    "Title=[]\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        Title.append(\"-\") \n",
    "    else:\n",
    "        Title.append(i.text)\n",
    "#Making a list and storing all the scraped years into it\n",
    "Year=[]    \n",
    "for i in year:\n",
    "    if i.text is None :\n",
    "        Year.append(\"-\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "#Making a list and storing all the scraped genres into it        \n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"-\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "#Making a list and storing all the scraped runtime into it        \n",
    "Runtime=[]\n",
    "for i in runtime:\n",
    "    if i.text is None :\n",
    "        Runtime.append(\"-\") \n",
    "    else:\n",
    "        Runtime.append(i.text)\n",
    "#Making a list and storing all the scraped ratingss into it        \n",
    "Ratings=[]\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        Ratings.append(\"-\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "#Making a list and storing all the scraped votes into it        \n",
    "Votes=[]\n",
    "for i in votes:\n",
    "    if i.text is None :\n",
    "        Votes.append(\"-\") \n",
    "    else:\n",
    "        Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb49e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,835,393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>874,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>879,319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>225,709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>169,584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>193,351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  1,835,393  \n",
       "1    51 min     8.7    874,161  \n",
       "2    44 min     8.2    879,319  \n",
       "3    60 min     7.6    264,212  \n",
       "4    43 min     7.6    225,709  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,790  \n",
       "96   50 min     7.8     55,397  \n",
       "97   42 min     8.1    169,584  \n",
       "98   45 min     7.1     35,120  \n",
       "99  572 min     8.6    193,351  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame\n",
    "Series=pd.DataFrame({})\n",
    "Series['Title']=Title \n",
    "Series['Year span']=Year\n",
    "Series['Genre']=Genre\n",
    "Series['Run time']=Runtime\n",
    "Series['Ratings']=Ratings\n",
    "Series['Votes']=Votes\n",
    "#Viewing the DataFrame\n",
    "Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa67436",
   "metadata": {},
   "source": [
    "10>Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "177d0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first connect to web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "# Opening the UCI machine learning website\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c145d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing all the datasets by passing xpath\n",
    "driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6201d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the data by passing xpath \n",
    "name = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[1]\")\n",
    "#Making a list and storing all the scraped names into it\n",
    "Name=[]\n",
    "for i in name:\n",
    "    if i.text is None :\n",
    "        Name.append(\"-\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "#Scraping the data by passing xpath         \n",
    "datatype=driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[2]\")\n",
    "#Making a list and storing all the scraped datatypes into it\n",
    "Datatype=[]\n",
    "for i in datatype:\n",
    "    if i.text is None :\n",
    "        Datatype.append(\"-\") \n",
    "    else:\n",
    "        Datatype.append(i.text)\n",
    "#Scraping the data by passing xpath\n",
    "task = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[3]\")\n",
    "#Making a list and storing all the scraped tasks into it\n",
    "Task=[]\n",
    "for i in task:\n",
    "    if i.text is None :\n",
    "        Task.append(\"-\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "#Scraping the data by passing xpath\n",
    "attribute_types = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[4]\")\n",
    "#Making a list and storing all the scraped attribute types into it\n",
    "Attribute_types=[]\n",
    "for i in attribute_types:\n",
    "    if i.text is None :\n",
    "        Attribute_types.append(\"-\") \n",
    "    else:\n",
    "        Attribute_types.append(i.text)\n",
    "#Scraping the data by passing xpath\n",
    "Instances_no = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[5]\")\n",
    "#Making a list and storing all the scraped instances number into it\n",
    "Instances=[]\n",
    "for i in Instances_no:\n",
    "    if i.text is None :\n",
    "        Instances.append(\"-\") \n",
    "    else:\n",
    "        Instances.append(i.text)\n",
    "#Scraping the data by passing xpath\n",
    "Attributes_no = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[6]\")\n",
    "#Making a list and storing all the scraped no. of attributes into it\n",
    "Attributes=[]\n",
    "for i in Attributes_no:\n",
    "    if i.text is None :\n",
    "        Attributes.append(\"-\") \n",
    "    else:\n",
    "        Attributes.append(i.text)\n",
    "        \n",
    "#Scraping the data by passing xpath\n",
    "year = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr/td[7]\")\n",
    "#Making a list and storing all the scraped years into it\n",
    "Year=[]\n",
    "for i in year:\n",
    "    if i.text is None :\n",
    "        Year.append(\"-\") \n",
    "    else:\n",
    "        Year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "679c50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 589 589 589 589 589\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of all the columns\n",
    "print(len(Name),len(Datatype),len(Attribute_types),len(Instances),len(Attributes),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9dfce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Instances</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name      Data Type  \\\n",
       "0                                  Name     Data Types   \n",
       "1                               Abalone  Multivariate    \n",
       "2                                 Adult  Multivariate    \n",
       "3                             Annealing  Multivariate    \n",
       "4          Anonymous Microsoft Web Data                  \n",
       "..                                  ...            ...   \n",
       "584    in-vehicle coupon recommendation  Multivariate    \n",
       "585                 Gait Classification  Multivariate    \n",
       "586           Wikipedia Math Essentials   Time-Series    \n",
       "587           Wikipedia Math Essentials   Time-Series    \n",
       "588        Synchronous Machine Data Set  Multivariate    \n",
       "\n",
       "                  Attribute Type No of Instances No of Attribute   Year  \n",
       "0                Attribute Types     # Instances    # Attributes   Year  \n",
       "1    Categorical, Integer, Real            4177               8   1995   \n",
       "2          Categorical, Integer           48842              14   1996   \n",
       "3    Categorical, Integer, Real             798              38          \n",
       "4                   Categorical           37711             294   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "584                                       12684              23   2020   \n",
       "585                        Real              48             321   2020   \n",
       "586                        Real             731            1068   2021   \n",
       "587                        Real             731            1068   2021   \n",
       "588                        Real             557               5   2021   \n",
       "\n",
       "[589 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving all the scraped data into a DataFrame(UCI)\n",
    "UCI=pd.DataFrame({})\n",
    "UCI['Dataset Name']=Name\n",
    "UCI['Data Type']=Datatype\n",
    "UCI['Attribute Type']=Attribute_types\n",
    "UCI['No of Instances']=Instances\n",
    "UCI['No of Attribute']=Attributes\n",
    "UCI['Year']=Year\n",
    "#Viewing the DataFrame\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a815c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
